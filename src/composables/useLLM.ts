import { ref } from 'vue'

export interface ThreadTweet {
  id: string
  content: string
  charCount: number
}

export const useLLM = () => {
  const isGenerating = ref(false)
  const error = ref<string | null>(null)

  // Modelos disponibles ordenados por preferencia
  const AVAILABLE_MODELS = [
    'claude-sonnet-4-latest',
    'openrouter:anthropic/claude-3.5-sonnet-20240620',
    'gpt-4o-mini',
    'openrouter:openai/gpt-4.1-mini',
  ]

  const checkPuterAvailability = (): boolean => {
    return typeof window !== 'undefined' && !!(window as any).puter?.ai?.chat
  }

  const selectBestAvailableModel = async (): Promise<string> => {
    if (!checkPuterAvailability()) {
      throw new Error('Puter.js no est√° disponible')
    }

    // Intentar cada modelo en orden de preferencia
    for (const model of AVAILABLE_MODELS) {
      try {
        // Hacer una prueba simple con cada modelo
        await (window as any).puter.ai.chat('test', {
          model,
          max_tokens: 1,
          temperature: 0,
        })
        return model
      } catch (err) {
        console.warn(`Model ${model} not available:`, err)
        continue
      }
    }

    // Fallback: usar el primer modelo sin especificar (deber√≠a usar el default)
    return AVAILABLE_MODELS[0]
  }

  const generateThread = async (text: string): Promise<ThreadTweet[]> => {
    isGenerating.value = true
    error.value = null

    try {
      // En desarrollo, mantener la simulaci√≥n
      if (import.meta.env.DEV && !checkPuterAvailability()) {
        await new Promise((resolve) => setTimeout(resolve, 2000))

        const mockTweets = [
          'üî• La transformaci√≥n digital en Am√©rica Latina es imparable: 85% de empresas aceleraron digitalizaci√≥n desde 2020. Ya no es opci√≥n, es supervivencia en la nueva econom√≠a.',

          'üí° Pero hay un gran PERO: la brecha digital golpea fuerte a las PYMES. Falta presupuesto y conocimiento t√©cnico para acceder a tecnolog√≠as avanzadas. Un problema que frena el crecimiento.',

          'ü§ù La soluci√≥n est√° clara: necesitamos pol√≠ticas p√∫blicas inteligentes, programas de capacitaci√≥n digital y alianzas estrat√©gicas sector p√∫blico-privado. Unidos podemos m√°s.',

          'üöÄ El futuro de Am√©rica Latina se define HOY: cerrar la brecha digital y convertir la tecnolog√≠a en motor de crecimiento inclusivo. ¬øEstamos listos para el desaf√≠o?',
        ]

        return mockTweets.map((content, index) => ({
          id: `tweet-${index + 1}`,
          content,
          charCount: content.length,
        }))
      }

      // Usar puter.ai en producci√≥n
      const model = await selectBestAvailableModel()

      const prompt = `
Convierte este editorial en un hilo de Twitter de m√°ximo 4 tweets.

REGLAS ESTRICTAS:
- Cada tweet debe tener m√°ximo 280 caracteres
- Mant√©n la esencia y los puntos clave del art√≠culo
- Usa emojis estrat√©gicamente para hacerlo m√°s atractivo
- El primer tweet debe captar atenci√≥n inmediatamente
- El √∫ltimo tweet debe tener call-to-action o reflexi√≥n poderosa
- Cada tweet debe funcionar de forma independiente pero conectar con los dem√°s
- Usa un tono profesional pero accesible

EDITORIAL:
${text.slice(0, 4000)} ${text.length > 4000 ? '...' : ''}

Formato de respuesta: devuelve SOLO los tweets, uno por l√≠nea, sin numeraci√≥n ni explicaciones adicionales.
      `

      const response = await (window as any).puter.ai.chat(prompt, {
        model,
        temperature: 0.8,
        max_tokens: 1000,
      })

      // Extraer contenido de la respuesta
      let content = ''
      if (typeof response === 'string') {
        content = response
      } else if (response.message?.content) {
        content = response.message.content
      } else if (response.valueOf) {
        content = response.valueOf()
      } else if (response.toString) {
        content = response.toString()
      }

      if (!content) {
        throw new Error('No se recibi√≥ contenido v√°lido del modelo de IA')
      }

      // Procesar la respuesta
      const tweets = content
        .split('\n')
        .map((line) => line.trim())
        .filter((line) => line.length > 0)
        .filter((line) => !line.match(/^\d+[\.\)\:]/)) // Remover numeraci√≥n si existe
        .slice(0, 4) // M√°ximo 4 tweets

      if (tweets.length === 0) {
        throw new Error('El modelo no gener√≥ tweets v√°lidos')
      }

      return tweets.map((content, index) => ({
        id: `tweet-${Date.now()}-${index + 1}`,
        content: content.trim(),
        charCount: content.trim().length,
      }))
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'Error al generar el hilo'
      error.value = errorMessage
      console.error('Error generating thread:', err)
      throw new Error(errorMessage)
    } finally {
      isGenerating.value = false
    }
  }

  const regenerateTweet = async (originalText: string, tweetIndex: number): Promise<string> => {
    try {
      // En desarrollo, usar alternativas mock
      if (import.meta.env.DEV && !checkPuterAvailability()) {
        const alternatives = [
          'üîÑ Versi√≥n alternativa del tweet con un enfoque diferente y mismo impacto...',
          '‚ú® Nueva perspectiva del mismo punto clave pero con otras palabras...',
          'üí´ Enfoque renovado manteniendo la esencia del mensaje original...',
        ]

        await new Promise((resolve) => setTimeout(resolve, 1000))
        return alternatives[tweetIndex % alternatives.length]
      }

      // Usar puter.ai para regenerar tweet espec√≠fico
      const model = await selectBestAvailableModel()

      const prompt = `
Regenera SOLO el tweet n√∫mero ${tweetIndex + 1} de un hilo sobre este contenido:

${originalText.slice(0, 2000)}

Requisitos:
- M√°ximo 280 caracteres
- Diferente perspectiva pero mismo mensaje clave
- Mant√©n el tono y estilo profesional
- Incluye emojis estrat√©gicos
- ${tweetIndex === 0 ? 'Debe captar atenci√≥n (es el primer tweet)' : ''}
- ${tweetIndex === 3 ? 'Debe incluir call-to-action o reflexi√≥n final' : ''}

Responde SOLO con el nuevo tweet, sin explicaciones.
      `

      const response = await (window as any).puter.ai.chat(prompt, {
        model,
        temperature: 0.9, // M√°s creatividad para variaciones
        max_tokens: 100,
      })

      // Extraer contenido
      let content = ''
      if (typeof response === 'string') {
        content = response
      } else if (response.message?.content) {
        content = response.message.content
      } else if (response.valueOf) {
        content = response.valueOf()
      } else if (response.toString) {
        content = response.toString()
      }

      return content.trim() || 'Error al regenerar tweet'
    } catch (err) {
      console.error('Error regenerating tweet:', err)
      throw new Error('Error al regenerar el tweet')
    }
  }

  const getAvailableModels = async (): Promise<string[]> => {
    if (!checkPuterAvailability()) {
      return []
    }

    const availableModels: string[] = []

    for (const model of AVAILABLE_MODELS) {
      try {
        await (window as any).puter.ai.chat('test', {
          model,
          max_tokens: 1,
        })
        availableModels.push(model)
      } catch {
        // Modelo no disponible
      }
    }

    return availableModels
  }

  return {
    generateThread,
    regenerateTweet,
    getAvailableModels,
    checkPuterAvailability,
    isGenerating,
    error,
  }
}
